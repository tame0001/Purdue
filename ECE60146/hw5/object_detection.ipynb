{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as tvt\n",
    "from torchinfo import summary\n",
    "from torchvision.ops import generalized_box_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW5Dataset(Dataset):\n",
    "    '''\n",
    "    This is a dataset class for this hw.\n",
    "    '''\n",
    "    LABELS = ['bus', 'cat', 'pizza'] # Labels for this task\n",
    "    TARGET_SIZE = 256 # Image size\n",
    "    def __init__(self, path, dataset) -> None:\n",
    "        super().__init__()\n",
    "        # Read meta data that stores ground truth bboxes and labels\n",
    "        path = path / 'hw5_dataset'\n",
    "        with open(path / 'metadata.json') as fp:\n",
    "            self.meta = json.load(fp)\n",
    "        self.image_folder = path / 'no_box' # Location for raw images\n",
    "        self.filenames = [] # Keep filename\n",
    "        for filename in self.image_folder.iterdir():\n",
    "            if re.findall(r'(\\w+)-(\\d+)', filename.stem)[0][0] == dataset:\n",
    "                self.filenames.append(filename)        \n",
    "        self.augment = tvt.Compose([ \n",
    "            tvt.ToTensor(), # Convert to tensor\n",
    "            tvt.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # Normalize\n",
    "            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        image = Image.open(filename) # Load image from filename\n",
    "        tensor = self.augment(image) # Apply transformation\n",
    "        meta = self.meta[filename.stem] \n",
    "        label = self.LABELS.index(meta['label']) # Read label\n",
    "        return {\n",
    "            'filename': str(filename), # For debug\n",
    "            'image': tensor,\n",
    "            # It comes as [[x1, x2] [y1, y2]] -> transpose then flatten\n",
    "            # So it will be [x1, y1, x2, y2]\n",
    "            'bbox': torch.tensor(meta['bbox01'], dtype=torch.float).T.flatten(),\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HW5Dataset(Path('/home/tam/git/ece60146/data'), 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW4Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(123008, 64)\n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        xc = self.fc2(x)\n",
    "        xb = self.fc3(x)\n",
    "\n",
    "        return xc, xb\n",
    "model = HW4Net().to(device)\n",
    "loss_fn_c = nn.CrossEntropyLoss()\n",
    "loss_fn_b = generalized_box_iou_loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=1e-3,\n",
    "    betas=(0.9, 0.99)\n",
    ")\n",
    "summary(model, input_size=(8, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train() # Set to training mode\n",
    "total_loss_c = 0 # Classfication loss\n",
    "total_loss_b = 0 # Regression loss\n",
    "for _, data in enumerate(dataloader):\n",
    "    images = data['image'].to(device)\n",
    "    labels = data['label'].to(device)\n",
    "    bboxes = data['bbox'].to(device)\n",
    "    pred_labels, pred_boxes = model(images) # Get prediction\n",
    "    loss_c = loss_fn_c(pred_labels, labels) # Calculate classification loss\n",
    "    total_loss_c += loss_c.item()\n",
    "    print(bboxes)\n",
    "    print(pred_boxes)\n",
    "    loss_b = loss_fn_b(pred_boxes, bboxes) # Calculate regression loss\n",
    "    total_loss_b += loss_b.item()\n",
    "    optimizer.zero_grad() # Reset gradient\n",
    "    loss_c.backward(retain_graph=True) # First backprop need extra setting\n",
    "    loss_b.backward()\n",
    "    optimizer.step() # Update parameters\n",
    "# Average loss over all batches\n",
    "total_loss_c /= len(dataloader)\n",
    "total_loss_b /= len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW5Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(3, 16, 7),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "        n_downsampling = 4\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model.extend([\n",
    "                nn.Conv2d(16*mult, 16*mult*2, 3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(16*mult*2),\n",
    "                nn.ReLU(True)\n",
    "            ])\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "model = HW5Net().to(device)\n",
    "summary(model, input_size=(8, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(list(model.parameters()))\n",
    "print(\"\\nThe number of layers in the model: %d\\n\\n\" % num_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
