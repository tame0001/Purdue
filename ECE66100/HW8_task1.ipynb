{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitece595conda838367ab88354209b4fac951afea76c5",
   "display_name": "Python 3.7.6 64-bit ('ece595': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import re\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = 'ece661_pics\\\\hw8_image\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image():\n",
    "    ''' \n",
    "        Class for storing images.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name    \n",
    "        self.image = None  \n",
    "        self.feature = None\n",
    "\n",
    "    def load(self):\n",
    "        self.image = cv.imread(self.name)\n",
    "        self.image_gray = cv.cvtColor(self.image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    def show(self):\n",
    "        if self.image is None:\n",
    "            self.load()\n",
    "        plt.imshow(cv.cvtColor(self.image, cv.COLOR_BGR2RGB))\n",
    "\n",
    "    def compute_gram_matrix(self, filters):\n",
    "        ''' \n",
    "            Compute Gram Matrix and \n",
    "            return only lower triangle part.\n",
    "        '''\n",
    "        \n",
    "        if self.image is None:\n",
    "            self.load()\n",
    "\n",
    "        img = self.image_gray\n",
    "        k = 16\n",
    "        C = filters.shape[2]\n",
    "        vectors = np.empty((k**2, C))\n",
    "        for c in range(C):\n",
    "            kernel = filters[:, :, c]\n",
    "            # Convolve with each filter\n",
    "            convolved = cv.filter2D(img, -1, kernel)\n",
    "            # Down scale to 16 x 16\n",
    "            down_scale = cv.resize(convolved, (k, k))\n",
    "            # vectorize to 256 element vector\n",
    "            vectors[:, c] = down_scale.ravel()\n",
    "\n",
    "        feature = []\n",
    "        for c in range(C):\n",
    "            for i in range(c):\n",
    "                # Inner product of each pair\n",
    "                feature.append(np.dot(vectors[:, c].T, vectors[:, i]))\n",
    "\n",
    "        self.feature = np.array(feature)\n",
    "\n",
    "        return self.feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_classes):\n",
    "    '''\n",
    "        Load images from database.\n",
    "    '''\n",
    "\n",
    "    trainning_set = {}\n",
    "    testing_set = {}\n",
    "    valid_set = {}\n",
    "    \n",
    "    for img_class in img_classes:\n",
    "        trainning_set[img_class] = []\n",
    "        testing_set[img_class] = []\n",
    "        valid_set[img_class] = []\n",
    "        # Load training sets\n",
    "        directory = f'{FILEPATH}training'\n",
    "        imgs = listdir(directory)\n",
    "        imgs_in_class = [re.findall(f'{img_class}.*', img) for img in imgs]\n",
    "        for img in imgs_in_class:\n",
    "            if img:\n",
    "                full_path = f'{directory}\\\\{img[0]}'\n",
    "                trainning_set[img_class].append(Image(full_path))\n",
    "\n",
    "        # Load testing set\n",
    "        directory = f'{FILEPATH}testing'\n",
    "        imgs = listdir(directory)\n",
    "        imgs_in_class = [re.findall(f'{img_class}.*', img) for img in imgs]\n",
    "        for img in imgs_in_class:\n",
    "            if img:\n",
    "                full_path = f'{directory}\\\\{img[0]}'\n",
    "                testing_set[img_class].append(Image(full_path))\n",
    "\n",
    "        # Create validation list\n",
    "        total_imgs = len(trainning_set[img_class])\n",
    "        valiation_ratio = 0.25\n",
    "        for i in range(int(valiation_ratio * total_imgs)):\n",
    "            idx = np.random.randint(0, total_imgs-i)\n",
    "            valid_set[img_class].append(trainning_set[img_class].pop(idx))\n",
    "\n",
    "    return trainning_set, testing_set, valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classes = ['rain', 'cloudy', 'shine', 'sunrise']\n",
    "[imgs_train, imgs_test, imgs_valid] = load_image(img_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter(C):\n",
    "    '''\n",
    "        Create 3 x 3 x C filter which vaule range from [-1, 1]\n",
    "        and the sum is 0.\n",
    "    '''\n",
    "    m = 3\n",
    "    filters = np.empty((m, m, C))\n",
    "    for c in range(C):\n",
    "        sample = np.random.rand(m**2)\n",
    "        sample -= sample.mean()\n",
    "        sample /= np.abs(sample).max()\n",
    "        filters[:, :, c] = sample.reshape((m ,m))\n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = create_filter(10)\n",
    "feature_size = imgs_train['rain'][0].compute_gram_matrix(filters).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_data = []\n",
    "labels = []\n",
    "for i, img_class in enumerate(img_classes):\n",
    "    for img in imgs_train[img_class]:\n",
    "        labels.append(i)\n",
    "        train_data.append(img.compute_gram_matrix(filters))\n",
    "\n",
    "labels = np.array(labels)\n",
    "train_data = np.array(train_data).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM parameters\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, 100, 1e-6))\n",
    "svm.train(train_data, cv.ml.ROW_SAMPLE, labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Validation accuracy = 35.32 %\n"
    },
    {
     "data": {
      "text/plain": "array([[15, 24,  7,  5],\n       [ 2, 11,  6, 53],\n       [10, 14,  9, 27],\n       [ 6, 19,  1, 60]], dtype=int64)"
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create validation  dataset\n",
    "valid_data = []\n",
    "true_labels = []\n",
    "for i, img_class in enumerate(img_classes):\n",
    "    for img in imgs_valid[img_class]:\n",
    "        true_labels.append(i)\n",
    "        valid_data.append(img.compute_gram_matrix(filters))\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "valid_data = np.array(valid_data).astype(np.float32)\n",
    "response = svm.predict(valid_data)[1]\n",
    "\n",
    "validation = []\n",
    "for i in range(len(response)):\n",
    "    validation.append(response[i][0] == true_labels[i])\n",
    "\n",
    "validation = np.array(validation, dtype=np.uint8)\n",
    "print(f'Validation accuracy = {validation.mean()*100:.2f} %')\n",
    "confusion_matrix(true_labels, response[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Testing accuracy = 35.00 %\n"
    },
    {
     "data": {
      "text/plain": "array([[5, 1, 2, 2],\n       [0, 3, 2, 5],\n       [1, 3, 0, 6],\n       [1, 2, 1, 6]], dtype=int64)"
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create testing dataset\n",
    "test_data = []\n",
    "true_labels = []\n",
    "for i, img_class in enumerate(img_classes):\n",
    "    for img in imgs_test[img_class]:\n",
    "        true_labels.append(i)\n",
    "        test_data.append(img.compute_gram_matrix(filters))\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "test_data = np.array(test_data).astype(np.float32)\n",
    "response = svm.predict(test_data)[1]\n",
    "\n",
    "result = []\n",
    "for i in range(len(response)):\n",
    "    # print(f' Truth {true_labels[i]} Predicted {response[i][0]} {response[i][0] == true_labels[i]}')\n",
    "    result.append(response[i][0] == true_labels[i])\n",
    "\n",
    "result = np.array(result, dtype=np.uint8)\n",
    "print(f'Testing accuracy = {result.mean()*100:.2f} %')\n",
    "confusion_matrix(true_labels, response[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "svm.save(f'{FILEPATH}model.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 0.53  -0.527 -0.948]\n [ 0.241  0.633  1.   ]\n [-0.875  0.615 -0.669]]\n[[-0.638  0.233  0.586]\n [ 0.823 -0.533 -0.674]\n [-0.077  1.    -0.72 ]]\n[[-0.315  0.032  0.446]\n [-0.446 -0.322 -0.199]\n [ 0.403  1.    -0.598]]\n[[-0.279  1.    -0.405]\n [ 0.191 -0.133  0.86 ]\n [-0.193 -0.401 -0.639]]\n[[ 0.75   0.348 -0.833]\n [ 0.09  -0.653 -0.714]\n [-0.442  0.454  1.   ]]\n[[-0.985 -0.916  0.787]\n [ 0.934  0.975  0.76 ]\n [-0.558 -1.     0.004]]\n[[ 0.246  0.472  1.   ]\n [-0.824  0.839  0.092]\n [-0.935 -0.598 -0.291]]\n[[-0.483 -0.881 -0.285]\n [ 0.463  0.707 -0.024]\n [ 0.326 -0.822  1.   ]]\n[[-0.361 -0.54   0.466]\n [ 1.     0.009 -0.477]\n [-0.264 -0.595  0.762]]\n[[ 0.248 -0.518  0.246]\n [ 0.643 -0.122 -0.221]\n [ 0.342  0.382 -1.   ]]\n"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "for f in range(filters.shape[2]):\n",
    "    print(filters[:, :, f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}